{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1IhQTwKRxGHoE_d4wbZzH2yGclr_LbHKM",
      "authorship_tag": "ABX9TyMUiovxbYTQrruFHTOMyTuO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pedroct06/Coloriza-o-de-fotos/blob/main/UpgradeCor_PedroTorres.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usei o dataset de colorização que eu encontrei no kaggle: https://www.kaggle.com/datasets/aayush9753/image-colorization-dataset/data"
      ],
      "metadata": {
        "id": "lW3mX80GuIAG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_2029Uk22yH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defino o tamanho das imagens para ser 128x128, e o caminho de onde está o meu dataSet"
      ],
      "metadata": {
        "id": "pdLJv0v6ts49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Img_size = 128\n",
        "dataset_path = kagglehub.dataset_download(\"aayush9753/image-colorization-dataset\")\n",
        "caminho_real = os.path.join(dataset_path, 'data')"
      ],
      "metadata": {
        "id": "V1yU2xiA3PHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializo duas listas vazias, no qual a primeira vai receber as imagens em preto e branco, que representa a entrada. Enquanto a outra recebe colorida, para guardar a saida. Além disso percorri as imagens presentes dentro da pasta de entrada, criando o caminho correto para serem processadas, transformando para 128x128. Após isso, eu converto de RGB para LAB, e separo a imagem em tres variáveis de canais: L, A, B.\n",
        "Divido a minha variável L por 255, para deixar os valores entre 0 e 1, e faço o reshape pois o canal L precisa ter o espaço para o canal de cor(AB).\n",
        "Após isso, eu junto os canais A e B, gerando uma imagem com 2 canais de cores, e faço a normalização subtraindo 128 e dividindo por 128, para ficar entre -1 e 1.\n",
        "Após tudo isso, adiciono nas duas listas criadas anteriormente, e retorno transformando para array de numpy, para poder utilizar no treinamento"
      ],
      "metadata": {
        "id": "0_bekfxFtzjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def carregar_imagem(input, esperado):\n",
        "    Icinza = []\n",
        "    Icor = []\n",
        "    arquivos = os.listdir(input)\n",
        "    for nome in arquivos:\n",
        "        caminho_saida = os.path.join(esperado, nome)\n",
        "\n",
        "        img_bgr = cv2.imread(caminho_saida)\n",
        "        img_bgr = cv2.resize(img_bgr, (Img_size, Img_size))\n",
        "\n",
        "        img_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "        l, a, b = cv2.split(img_lab)\n",
        "\n",
        "        img_input_l = l / 255.0\n",
        "        img_input_l = img_input_l.reshape(Img_size, Img_size, 1)\n",
        "\n",
        "        ab = np.stack((a, b), axis=2)\n",
        "\n",
        "        img_out_ab = (ab - 128.0) / 128.0\n",
        "\n",
        "        Icinza.append(img_input_l)\n",
        "        Icor.append(img_out_ab)\n",
        "    return np.array(Icinza), np.array(Icor)"
      ],
      "metadata": {
        "id": "qICPAK295PA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pego os arquivos pelos caminhos"
      ],
      "metadata": {
        "id": "QUGw1qIOvaPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "treino_cinza = os.path.join(caminho_real, 'train_black')\n",
        "treino_cor = os.path.join(caminho_real, 'train_color')\n",
        "teste_cinza = os.path.join(caminho_real, 'test_black')\n",
        "teste_cor = os.path.join(caminho_real, 'test_color')"
      ],
      "metadata": {
        "id": "yg17mmICDLWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pego os dois arrays retornados na função de carregar a imagem. Separando em treino e teste"
      ],
      "metadata": {
        "id": "l75p98fyv0XA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = carregar_imagem(treino_cinza, treino_cor)\n",
        "X_test, Y_test = carregar_imagem(teste_cinza, teste_cor)"
      ],
      "metadata": {
        "id": "GtLSm9ocDiWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "AT3r90g_QvID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defino a minha rede neural, peguei de modelo uma rede do tipo U-net que funciona como um funil.\n",
        "Primeiro passo eu recebi a minha imagem no modelo 128x128x1\n",
        "Depois eu vou diminuindo o tamanho da imagem pela metade, enquanto dobro a quantidade de detalhes e uso a função de ativação relu(C1,C2,C3)\n",
        "B é o local onde a imagem está menor, porém com muitos detalhes. Após isso, comeco a aumentar a imagem novamente (U1), aumentando de 16x16 para 32x32, e concatenando com informação do mesmo tamanho(C1,C2,C3), para retomar a espacialização perdida quando foi diminuindo.\n",
        "\n",
        "Na saída só temos dois filtros, para prever A e B, e uso a função de ativação tanh, pois normalizei os dados entre -1 e 1. E preciso de números negativos para representar as cores, logo não poderia usar a sigmoid nem relu\n",
        "Depois crio o modelo com o input e output criados"
      ],
      "metadata": {
        "id": "olpjNAAfwD5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rede_neural():\n",
        "    inputs = Input(shape = (Img_size, Img_size, 1))\n",
        "\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same', strides =2)(inputs)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same', strides = 2)(c1)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same', strides =2 )(c2)\n",
        "\n",
        "    b = Conv2D(512, (3, 3), activation='relu', padding='same')(c3)\n",
        "\n",
        "    u1 = Conv2DTranspose(256, (3, 3), activation='relu', padding='same', strides = 2)(b)\n",
        "    merge = Concatenate()([u1, c2])\n",
        "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge)\n",
        "\n",
        "    u2= Conv2DTranspose(128, (3, 3), activation='relu', padding='same', strides = 2)(c4)\n",
        "    merge = Concatenate()([u2, c1])\n",
        "    c5 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge)\n",
        "\n",
        "    u3 = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides = 2)(c5)\n",
        "    merge = Concatenate()([u3, inputs])\n",
        "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge)\n",
        "\n",
        "    outputs = Conv2D(2, (3, 3), activation='tanh', padding='same')(c6)\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "W0Cc1xUVDz3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilei o meu modelo, utilizando otimizador adam, pois se adapta a muitas situações. E utilizei a função de custo MAE, pois demonstrou um desempenho melhor do que a MSE(Calcula o erro absoluto médio, porém sem elevar ao quadrado), realizei o teste das duas"
      ],
      "metadata": {
        "id": "f6LfNt4w4dZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = rede_neural()\n",
        "model.compile(optimizer='adam', loss='mae')"
      ],
      "metadata": {
        "id": "URFyyH4RI42A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizei o treino com os dados de treino, utilizei 100 épocas(quantidade de vezes que meu conjunto de treino vai ser visto), os conjuntos de pesos só serão ajustados após passar por 32 fotos, na qual ela calcula o erro e passa pras outras 32. Utilizei também a validation_data para ver se a minha rede neural não está decorando para os casos de treino (overfitting)"
      ],
      "metadata": {
        "id": "hc3XEUWt5k1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "id": "WNdHxy1CI9iP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui eu fiz a função para carregar a minha imagem e plotar o gráfico com a minha colorida, e com a original. Ela faz o inverso da normalização dos dados, para poder formar uma imagem"
      ],
      "metadata": {
        "id": "2Pyi_GXr6nj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ver_imagem(i):\n",
        "  L_input = X_test[i]\n",
        "  ab_predict = model.predict(L_input.reshape(1, 128, 128, 1))[0]\n",
        "  L_ajustado = L_input * 100.0\n",
        "  ab_ajustado = (ab_predict * 128.0) * 3\n",
        "  LAB = np.concatenate([L_ajustado, ab_ajustado], axis=2)\n",
        "  RGB = cv2.cvtColor(LAB.astype('float32'), cv2.COLOR_LAB2RGB)\n",
        "  RGB = np.clip(RGB, 0, 1)\n",
        "\n",
        "  ab_real = Y_test[i]\n",
        "  ab_real_ajustado = ab_real * 128.0\n",
        "  LAB_real = np.concatenate([L_input * 100.0, ab_real_ajustado], axis=2)\n",
        "  RGB_real = cv2.cvtColor(LAB_real.astype('float32'), cv2.COLOR_LAB2RGB)\n",
        "  RGB_real = np.clip(RGB_real, 0, 1)\n",
        "\n",
        "  plt.figure(figsize = (12,6))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.title(\"imagem colorida\")\n",
        "  plt.imshow(RGB)\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.title(\"imagem colorida real\")\n",
        "  plt.imshow(RGB_real)\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "p6mCvTdLd7Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ver_imagem(1)"
      ],
      "metadata": {
        "id": "JgITLoCzh-rQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
# ColorizaÃ§Ã£o AutomÃ¡tica de Imagens com Deep Learning

Este notebook implementa uma **rede neural U-Net** para colorizaÃ§Ã£o automÃ¡tica de imagens em preto e branco usando TensorFlow/Keras.

## ğŸ“‹ DescriÃ§Ã£o

O projeto utiliza deep learning para aprender a colorizar imagens automaticamente, transformando fotos em escala de cinza em imagens coloridas realistas. A abordagem utiliza o espaÃ§o de cores **LAB** (LuminÃ¢ncia, A, B) ao invÃ©s de RGB para melhor separaÃ§Ã£o entre luminosidade e informaÃ§Ã£o de cor.

## ğŸ¨ Como Funciona

### EspaÃ§o de Cores LAB

- **L (LuminÃ¢ncia)**: Representa a escala de cinza (0-100)
- **A**: Canal de cor verde-vermelho (-128 a +127)
- **B**: Canal de cor azul-amarelo (-128 a +127)

**Vantagem**: Separar luminosidade (L) da informaÃ§Ã£o de cor (A, B) permite que a rede aprenda apenas a adicionar cor, mantendo a estrutura original da imagem.

## ğŸ› ï¸ Requisitos

```bash
pip install tensorflow
pip install opencv-python
pip install kagglehub
pip install matplotlib
pip install scikit-learn
```

Bibliotecas utilizadas:
- tensorflow/keras
- numpy
- opencv-python (cv2)
- matplotlib
- scikit-learn
- kagglehub

## ğŸ“ Dataset

**Image Colorization Dataset**
- Fonte: Kaggle (`aayush9753/image-colorization-dataset`)
- Estrutura:
  - `train_black/` - Imagens de treino em preto e branco
  - `train_color/` - Imagens de treino coloridas
  - `test_black/` - Imagens de teste em preto e branco
  - `test_color/` - Imagens de teste coloridas
- Tamanho das imagens: Redimensionadas para 128Ã—128 pixels

## ğŸ”„ Pipeline de Processamento

### 1. Carregamento e PreparaÃ§Ã£o dos Dados

```python
def carregar_imagem(input, esperado):
    # Para cada imagem:
    # 1. Carregar e redimensionar para 128x128
    img_bgr = cv2.imread(caminho)
    img_bgr = cv2.resize(img_bgr, (128, 128))
    
    # 2. Converter de BGR para LAB
    img_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    
    # 3. Separar canais
    l, a, b = cv2.split(img_lab)
    
    # 4. Normalizar canal L (entrada): [0, 255] â†’ [0, 1]
    img_input_l = l / 255.0
    
    # 5. Normalizar canais AB (saÃ­da): [0, 255] â†’ [-1, 1]
    img_out_ab = (ab - 128.0) / 128.0
    
    return np.array(Icinza), np.array(Icor)
```

### NormalizaÃ§Ã£o Explicada

| Canal | Intervalo Original | NormalizaÃ§Ã£o | Intervalo Final |
|-------|-------------------|--------------|-----------------|
| **L** | 0 - 255 | `L / 255.0` | 0.0 - 1.0 |
| **A, B** | 0 - 255 | `(AB - 128) / 128` | -1.0 - 1.0 |

## ğŸ—ï¸ Arquitetura U-Net

### Estrutura da Rede

A U-Net Ã© uma arquitetura encoder-decoder com conexÃµes skip:

```
Entrada (128Ã—128Ã—1)
    â†“
â”Œâ”€â”€â”€ Encoder (ContraÃ§Ã£o) â”€â”€â”€â”
â”‚   C1: 128Ã—128Ã—64 â†’ 64Ã—64   â”‚
â”‚   C2: 64Ã—64Ã—128 â†’ 32Ã—32    â”‚
â”‚   C3: 32Ã—32Ã—256 â†’ 16Ã—16    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    Bottleneck (16Ã—16Ã—512)
            â†“
â”Œâ”€â”€â”€ Decoder (ExpansÃ£o) â”€â”€â”€â”€â”€â”
â”‚   U1: 16Ã—16 â†’ 32Ã—32Ã—256    â”‚â”€â”€â”
â”‚   Concatenate com C2        â”‚  â”‚ Skip Connections
â”‚   U2: 32Ã—32 â†’ 64Ã—64Ã—128    â”‚â”€â”€â”¤ (preservam detalhes)
â”‚   Concatenate com C1        â”‚  â”‚
â”‚   U3: 64Ã—64 â†’ 128Ã—128Ã—64   â”‚â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    SaÃ­da (128Ã—128Ã—2)
```

### ImplementaÃ§Ã£o do Modelo

```python
def rede_neural():
    inputs = Input(shape=(128, 128, 1))
    
    # Encoder - Reduz dimensÃ£o espacial, aumenta profundidade
    c1 = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(inputs)
    c2 = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(c1)
    c3 = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(c2)
    
    # Bottleneck - Maior profundidade, menor dimensÃ£o
    b = Conv2D(512, (3,3), activation='relu', padding='same')(c3)
    
    # Decoder - Aumenta dimensÃ£o espacial, reduz profundidade
    u1 = Conv2DTranspose(256, (3,3), activation='relu', strides=2)(b)
    merge = Concatenate()([u1, c2])  # Skip connection
    c4 = Conv2D(256, (3,3), activation='relu', padding='same')(merge)
    
    u2 = Conv2DTranspose(128, (3,3), activation='relu', strides=2)(c4)
    merge = Concatenate()([u2, c1])  # Skip connection
    c5 = Conv2D(128, (3,3), activation='relu', padding='same')(merge)
    
    u3 = Conv2DTranspose(64, (3,3), activation='relu', strides=2)(c5)
    merge = Concatenate()([u3, inputs])  # Skip connection
    c6 = Conv2D(64, (3,3), activation='relu', padding='same')(merge)
    
    # SaÃ­da - 2 canais (A e B)
    outputs = Conv2D(2, (3,3), activation='tanh', padding='same')(c6)
    
    return Model(inputs=[inputs], outputs=[outputs])
```

### Componentes Principais

#### Conv2D (ConvoluÃ§Ã£o)
- Extrai caracterÃ­sticas das imagens
- Filtros 3Ã—3 para detectar padrÃµes
- `padding='same'`: mantÃ©m dimensÃµes
- `strides=2`: reduz dimensÃ£o pela metade

#### Conv2DTranspose (DeconvoluÃ§Ã£o)
- Aumenta resoluÃ§Ã£o espacial
- ReconstrÃ³i detalhes da imagem
- `strides=2`: dobra a dimensÃ£o

#### Concatenate (Skip Connections)
- Une features do encoder com decoder
- Recupera detalhes espaciais perdidos
- **Essencial para qualidade da imagem**

#### FunÃ§Ãµes de AtivaÃ§Ã£o
- **ReLU** (`relu`): Camadas intermediÃ¡rias
  - Introduz nÃ£o-linearidade
  - Computacionalmente eficiente
- **Tanh** (`tanh`): Camada de saÃ­da
  - Retorna valores em [-1, 1]
  - NecessÃ¡rio pois AB foi normalizado neste intervalo

## ğŸ¯ Treinamento

### ConfiguraÃ§Ã£o

```python
model = rede_neural()
model.compile(
    optimizer='adam',      # Otimizador adaptativo
    loss='mae'            # Mean Absolute Error
)
```

### Escolhas de Design

| ParÃ¢metro | Valor | Justificativa |
|-----------|-------|---------------|
| **Otimizador** | Adam | Adaptativo, converge rÃ¡pido, funciona bem em muitos cenÃ¡rios |
| **FunÃ§Ã£o de Perda** | MAE | Melhor que MSE para esta tarefa, menos sensÃ­vel a outliers |
| **Ã‰pocas** | 100 | NÃºmero de vezes que o dataset completo Ã© processado |
| **Batch Size** | 32 | Compromisso entre memÃ³ria e convergÃªncia |

### ExecuÃ§Ã£o do Treinamento

```python
model.fit(
    X_train, Y_train,
    epochs=100,
    batch_size=32,
    validation_data=(X_test, Y_test)
)
```

**validation_data**: Previne overfitting ao monitorar performance em dados nÃ£o vistos

## ğŸ“Š VisualizaÃ§Ã£o de Resultados

### FunÃ§Ã£o de VisualizaÃ§Ã£o

```python
def ver_imagem(i):
    # 1. Prever canais AB
    L_input = X_test[i]
    ab_predict = model.predict(L_input.reshape(1, 128, 128, 1))[0]
    
    # 2. Desnormalizar
    L_ajustado = L_input * 100.0           # [0,1] â†’ [0,100]
    ab_ajustado = (ab_predict * 128.0) * 3  # [-1,1] â†’ [-128,127] com boost
    
    # 3. Recombinar LAB
    LAB = np.concatenate([L_ajustado, ab_ajustado], axis=2)
    
    # 4. Converter LAB â†’ RGB
    RGB = cv2.cvtColor(LAB.astype('float32'), cv2.COLOR_LAB2RGB)
    RGB = np.clip(RGB, 0, 1)
    
    # 5. Plotar lado a lado
    plt.subplot(1, 2, 1)
    plt.imshow(RGB)  # PrediÃ§Ã£o
    
    plt.subplot(1, 2, 2)
    plt.imshow(RGB_real)  # Original
```

### Processo de ReconstruÃ§Ã£o

1. **Entrada**: Imagem em escala de cinza (canal L)
2. **PrediÃ§Ã£o**: Rede neural gera canais A e B
3. **DesnormalizaÃ§Ã£o**: Reverter transformaÃ§Ãµes
4. **RecombinaÃ§Ã£o**: Juntar L + AB â†’ LAB
5. **ConversÃ£o**: LAB â†’ RGB para visualizaÃ§Ã£o
6. **Clipping**: Garantir valores vÃ¡lidos [0, 1]

## ğŸš€ Como Usar

### 1. Preparar o Ambiente

```python
# Baixar dataset do Kaggle
dataset_path = kagglehub.dataset_download("aayush9753/image-colorization-dataset")

# Configurar caminhos
treino_cinza = os.path.join(dataset_path, 'data/train_black')
treino_cor = os.path.join(dataset_path, 'data/train_color')
teste_cinza = os.path.join(dataset_path, 'data/test_black')
teste_cor = os.path.join(dataset_path, 'data/test_color')
```

### 2. Carregar Dados

```python
X_train, Y_train = carregar_imagem(treino_cinza, treino_cor)
X_test, Y_test = carregar_imagem(teste_cinza, teste_cor)
```

### 3. Treinar Modelo

```python
model = rede_neural()
model.compile(optimizer='adam', loss='mae')
model.fit(X_train, Y_train, epochs=100, batch_size=32, 
          validation_data=(X_test, Y_test))
```

### 4. Visualizar Resultados

```python
# Ver colorizaÃ§Ã£o da primeira imagem de teste
ver_imagem(0)

# Ver outras imagens
ver_imagem(5)
ver_imagem(10)
```

## ğŸ’¡ Insights TÃ©cnicos

### Por que U-Net?

1. **Skip Connections**: Preservam detalhes espaciais durante upsampling
2. **Simetria**: Encoder e decoder balanceados
3. **Comprovada**: Excelente para tarefas de segmentaÃ§Ã£o e colorizaÃ§Ã£o

### Por que EspaÃ§o LAB?

1. **SeparaÃ§Ã£o Natural**: L contÃ©m estrutura, AB contÃ©m cor
2. **Perceptualmente Uniforme**: MudanÃ§as numÃ©ricas correspondem a mudanÃ§as visuais
3. **Facilita Aprendizado**: Rede foca apenas em adicionar cor

### Detalhes de ImplementaÃ§Ã£o

- **Multiplicador Ã—3 no AB**: Intensifica cores na reconstruÃ§Ã£o
- **GPU Recomendada**: Treinamento Ã© intensivo (T4 no Colab)
- **Imagens 128Ã—128**: Compromisso entre qualidade e velocidade

## ğŸ“ˆ Melhorias PossÃ­veis

### Arquitetura
- Aumentar resoluÃ§Ã£o para 256Ã—256 ou 512Ã—512
- Adicionar mais camadas no bottleneck
- Implementar attention mechanisms

### Treinamento
- Data augmentation (rotaÃ§Ã£o, flip, zoom)
- Learning rate scheduling
- Early stopping com checkpoint

### PÃ³s-processamento
- Ajuste fino de saturaÃ§Ã£o/brilho
- Ensemble de mÃºltiplos modelos
- Refinamento com GANs

## âš ï¸ LimitaÃ§Ãµes

- **ResoluÃ§Ã£o**: 128Ã—128 pode perder detalhes finos
- **Ambiguidade**: Alguns objetos podem ter mÃºltiplas cores vÃ¡lidas
- **Dataset**: Performance depende da qualidade dos dados de treino
- **Recursos**: Requer GPU para treinamento eficiente

## ğŸ”— Links Ãšteis

- [U-Net Paper](https://arxiv.org/abs/1505.04597)
- [LAB Color Space](https://en.wikipedia.org/wiki/CIELAB_color_space)
- [TensorFlow/Keras Documentation](https://www.tensorflow.org/api_docs/python/tf/keras)
- [Dataset Kaggle](https://www.kaggle.com/datasets/aayush9753/image-colorization-dataset)

## ğŸ“„ LicenÃ§a

Este notebook estÃ¡ disponÃ­vel no GitHub: [ColorizaÃ§Ã£o de fotos](https://github.com/Pedroct06/Coloriza-o-de-fotos)

---

**Nota**: Este Ã© um projeto educacional demonstrando tÃ©cnicas de deep learning para processamento de imagens. Os resultados podem variar dependendo do dataset e hiperparÃ¢metros utilizados.
